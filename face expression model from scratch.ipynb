{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "440d7eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from tensorflow import keras\n",
    "tf.config.experimental.set_visible_devices([], 'GPU')\n",
    "from  matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b67f4bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = r\"C:\\Users\\amr\\images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "494cfc6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28821 images belonging to 7 classes.\n",
      "Found 7066 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "Batch_size = 128\n",
    "train_gen = ImageDataGenerator()\n",
    "test_gen = ImageDataGenerator()\n",
    "train_set = train_gen.flow_from_directory(images+\"/train\" , \n",
    "                                         color_mode=\"grayscale\",\n",
    "                                         batch_size=Batch_size,\n",
    "                                         target_size = (48,48),\n",
    "                                         class_mode=\"categorical\",\n",
    "                                          shuffle=True)\n",
    "\n",
    "test_set = test_gen.flow_from_directory(images+\"/validation\" , \n",
    "                                         color_mode=\"grayscale\",\n",
    "                                         batch_size=Batch_size,\n",
    "                                         target_size = (48,48),\n",
    "                                         class_mode=\"categorical\",\n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3361cdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_classes = 7\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(16 , (5,5) , padding=\"SAME\" , activation=\"relu\" , input_shape = [48,48,1]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPooling2D((2,2)),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Conv2D(32 , (3,3) , padding=\"SAME\" , activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPooling2D((2,2)),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Conv2D(64 , (3,3) , padding=\"SAME\" , activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPooling2D((2,2)),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Conv2D(128 , (3,3) , padding=\"SAME\" , activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPooling2D((2,2)),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(200 , activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(100 , activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(no_of_classes , activation=\"softmax\"),\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bcd9d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=opt , loss='categorical_crossentropy' , metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2060595e",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                          min_delta=0,\n",
    "                          patience=3,\n",
    "                          verbose=1,\n",
    "                          restore_best_weights=True\n",
    "                          )\n",
    "\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(r\"C:\\Users\\amr\\Emotion Detection 2/model.h\", monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "reduce_learningrate = keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
    "                              factor=0.2,\n",
    "                              patience=3,\n",
    "                              verbose=1,\n",
    "                              min_delta=0.0001)\n",
    "\n",
    "callbacks_list = [early_stopping,reduce_learningrate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "968f2ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amr\\AppData\\Local\\Temp\\ipykernel_12796\\848135606.py:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(generator=train_set , steps_per_epoch=train_set.n//train_set.batch_size,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 71s 303ms/step - loss: 2.0493 - accuracy: 0.2103 - val_loss: 1.7966 - val_accuracy: 0.2746 - lr: 1.0000e-04\n",
      "Epoch 2/48\n",
      "225/225 [==============================] - 68s 303ms/step - loss: 1.8329 - accuracy: 0.2464 - val_loss: 1.7323 - val_accuracy: 0.2996 - lr: 1.0000e-04\n",
      "Epoch 3/48\n",
      "225/225 [==============================] - 70s 309ms/step - loss: 1.7916 - accuracy: 0.2631 - val_loss: 1.7068 - val_accuracy: 0.3081 - lr: 1.0000e-04\n",
      "Epoch 4/48\n",
      "225/225 [==============================] - 68s 304ms/step - loss: 1.7627 - accuracy: 0.2769 - val_loss: 1.6836 - val_accuracy: 0.3338 - lr: 1.0000e-04\n",
      "Epoch 5/48\n",
      "225/225 [==============================] - 68s 303ms/step - loss: 1.7402 - accuracy: 0.2908 - val_loss: 1.6597 - val_accuracy: 0.3335 - lr: 1.0000e-04\n",
      "Epoch 6/48\n",
      "225/225 [==============================] - 70s 310ms/step - loss: 1.7129 - accuracy: 0.3077 - val_loss: 1.6368 - val_accuracy: 0.3506 - lr: 1.0000e-04\n",
      "Epoch 7/48\n",
      "225/225 [==============================] - 69s 305ms/step - loss: 1.6928 - accuracy: 0.3238 - val_loss: 1.6111 - val_accuracy: 0.3669 - lr: 1.0000e-04\n",
      "Epoch 8/48\n",
      "225/225 [==============================] - 68s 304ms/step - loss: 1.6661 - accuracy: 0.3378 - val_loss: 1.5856 - val_accuracy: 0.3788 - lr: 1.0000e-04\n",
      "Epoch 9/48\n",
      "225/225 [==============================] - 69s 305ms/step - loss: 1.6470 - accuracy: 0.3470 - val_loss: 1.5607 - val_accuracy: 0.3911 - lr: 1.0000e-04\n",
      "Epoch 10/48\n",
      "225/225 [==============================] - 69s 307ms/step - loss: 1.6197 - accuracy: 0.3608 - val_loss: 1.5514 - val_accuracy: 0.3962 - lr: 1.0000e-04\n",
      "Epoch 11/48\n",
      "225/225 [==============================] - 69s 305ms/step - loss: 1.5962 - accuracy: 0.3726 - val_loss: 1.5106 - val_accuracy: 0.4190 - lr: 1.0000e-04\n",
      "Epoch 12/48\n",
      "225/225 [==============================] - 68s 303ms/step - loss: 1.5770 - accuracy: 0.3818 - val_loss: 1.5033 - val_accuracy: 0.4141 - lr: 1.0000e-04\n",
      "Epoch 13/48\n",
      "225/225 [==============================] - 68s 304ms/step - loss: 1.5517 - accuracy: 0.3909 - val_loss: 1.4672 - val_accuracy: 0.4291 - lr: 1.0000e-04\n",
      "Epoch 14/48\n",
      "225/225 [==============================] - 69s 307ms/step - loss: 1.5354 - accuracy: 0.4013 - val_loss: 1.4881 - val_accuracy: 0.4261 - lr: 1.0000e-04\n",
      "Epoch 15/48\n",
      "225/225 [==============================] - 69s 308ms/step - loss: 1.5177 - accuracy: 0.4079 - val_loss: 1.4492 - val_accuracy: 0.4374 - lr: 1.0000e-04\n",
      "Epoch 16/48\n",
      "225/225 [==============================] - 69s 304ms/step - loss: 1.5024 - accuracy: 0.4123 - val_loss: 1.4251 - val_accuracy: 0.4456 - lr: 1.0000e-04\n",
      "Epoch 17/48\n",
      "225/225 [==============================] - 69s 308ms/step - loss: 1.4914 - accuracy: 0.4187 - val_loss: 1.4074 - val_accuracy: 0.4571 - lr: 1.0000e-04\n",
      "Epoch 18/48\n",
      "225/225 [==============================] - 69s 308ms/step - loss: 1.4740 - accuracy: 0.4278 - val_loss: 1.4391 - val_accuracy: 0.4484 - lr: 1.0000e-04\n",
      "Epoch 19/48\n",
      "225/225 [==============================] - 69s 308ms/step - loss: 1.4565 - accuracy: 0.4360 - val_loss: 1.3904 - val_accuracy: 0.4651 - lr: 1.0000e-04\n",
      "Epoch 20/48\n",
      "225/225 [==============================] - 69s 307ms/step - loss: 1.4489 - accuracy: 0.4377 - val_loss: 1.4157 - val_accuracy: 0.4605 - lr: 1.0000e-04\n",
      "Epoch 21/48\n",
      "225/225 [==============================] - 69s 306ms/step - loss: 1.4320 - accuracy: 0.4444 - val_loss: 1.3885 - val_accuracy: 0.4662 - lr: 1.0000e-04\n",
      "Epoch 22/48\n",
      "225/225 [==============================] - 70s 309ms/step - loss: 1.4191 - accuracy: 0.4482 - val_loss: 1.3387 - val_accuracy: 0.4859 - lr: 1.0000e-04\n",
      "Epoch 23/48\n",
      "225/225 [==============================] - 69s 308ms/step - loss: 1.4130 - accuracy: 0.4554 - val_loss: 1.3247 - val_accuracy: 0.4903 - lr: 1.0000e-04\n",
      "Epoch 24/48\n",
      "225/225 [==============================] - 69s 308ms/step - loss: 1.3927 - accuracy: 0.4645 - val_loss: 1.3255 - val_accuracy: 0.4899 - lr: 1.0000e-04\n",
      "Epoch 25/48\n",
      "225/225 [==============================] - 69s 306ms/step - loss: 1.3844 - accuracy: 0.4658 - val_loss: 1.3091 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 26/48\n",
      "225/225 [==============================] - 68s 304ms/step - loss: 1.3732 - accuracy: 0.4680 - val_loss: 1.2995 - val_accuracy: 0.5024 - lr: 1.0000e-04\n",
      "Epoch 27/48\n",
      "225/225 [==============================] - 69s 308ms/step - loss: 1.3615 - accuracy: 0.4755 - val_loss: 1.2870 - val_accuracy: 0.5036 - lr: 1.0000e-04\n",
      "Epoch 28/48\n",
      "225/225 [==============================] - 69s 304ms/step - loss: 1.3509 - accuracy: 0.4763 - val_loss: 1.2811 - val_accuracy: 0.5077 - lr: 1.0000e-04\n",
      "Epoch 29/48\n",
      "225/225 [==============================] - 68s 304ms/step - loss: 1.3430 - accuracy: 0.4846 - val_loss: 1.2783 - val_accuracy: 0.5139 - lr: 1.0000e-04\n",
      "Epoch 30/48\n",
      "225/225 [==============================] - 69s 307ms/step - loss: 1.3293 - accuracy: 0.4881 - val_loss: 1.2658 - val_accuracy: 0.5158 - lr: 1.0000e-04\n",
      "Epoch 31/48\n",
      "225/225 [==============================] - 68s 304ms/step - loss: 1.3266 - accuracy: 0.4895 - val_loss: 1.2844 - val_accuracy: 0.5119 - lr: 1.0000e-04\n",
      "Epoch 32/48\n",
      "225/225 [==============================] - 69s 306ms/step - loss: 1.3164 - accuracy: 0.4937 - val_loss: 1.2465 - val_accuracy: 0.5253 - lr: 1.0000e-04\n",
      "Epoch 33/48\n",
      "225/225 [==============================] - 69s 306ms/step - loss: 1.3044 - accuracy: 0.4994 - val_loss: 1.2559 - val_accuracy: 0.5233 - lr: 1.0000e-04\n",
      "Epoch 34/48\n",
      "225/225 [==============================] - 69s 308ms/step - loss: 1.2967 - accuracy: 0.5009 - val_loss: 1.2368 - val_accuracy: 0.5315 - lr: 1.0000e-04\n",
      "Epoch 35/48\n",
      "225/225 [==============================] - 70s 309ms/step - loss: 1.2880 - accuracy: 0.5060 - val_loss: 1.2291 - val_accuracy: 0.5339 - lr: 1.0000e-04\n",
      "Epoch 36/48\n",
      "225/225 [==============================] - 70s 309ms/step - loss: 1.2821 - accuracy: 0.5070 - val_loss: 1.2291 - val_accuracy: 0.5347 - lr: 1.0000e-04\n",
      "Epoch 37/48\n",
      "225/225 [==============================] - 69s 308ms/step - loss: 1.2731 - accuracy: 0.5110 - val_loss: 1.2255 - val_accuracy: 0.5310 - lr: 1.0000e-04\n",
      "Epoch 38/48\n",
      "225/225 [==============================] - 70s 309ms/step - loss: 1.2621 - accuracy: 0.5149 - val_loss: 1.2132 - val_accuracy: 0.5401 - lr: 1.0000e-04\n",
      "Epoch 39/48\n",
      "225/225 [==============================] - 70s 310ms/step - loss: 1.2558 - accuracy: 0.5192 - val_loss: 1.2483 - val_accuracy: 0.5286 - lr: 1.0000e-04\n",
      "Epoch 40/48\n",
      "225/225 [==============================] - 70s 309ms/step - loss: 1.2448 - accuracy: 0.5195 - val_loss: 1.2064 - val_accuracy: 0.5437 - lr: 1.0000e-04\n",
      "Epoch 41/48\n",
      "225/225 [==============================] - 69s 308ms/step - loss: 1.2469 - accuracy: 0.5219 - val_loss: 1.1965 - val_accuracy: 0.5503 - lr: 1.0000e-04\n",
      "Epoch 42/48\n",
      "225/225 [==============================] - 71s 315ms/step - loss: 1.2373 - accuracy: 0.5261 - val_loss: 1.1992 - val_accuracy: 0.5477 - lr: 1.0000e-04\n",
      "Epoch 43/48\n",
      "225/225 [==============================] - 59s 260ms/step - loss: 1.2253 - accuracy: 0.5310 - val_loss: 1.1894 - val_accuracy: 0.5514 - lr: 1.0000e-04\n",
      "Epoch 44/48\n",
      "225/225 [==============================] - 47s 208ms/step - loss: 1.2175 - accuracy: 0.5336 - val_loss: 1.2333 - val_accuracy: 0.5412 - lr: 1.0000e-04\n",
      "Epoch 45/48\n",
      "225/225 [==============================] - 47s 210ms/step - loss: 1.2124 - accuracy: 0.5373 - val_loss: 1.1741 - val_accuracy: 0.5557 - lr: 1.0000e-04\n",
      "Epoch 46/48\n",
      "225/225 [==============================] - 47s 209ms/step - loss: 1.2010 - accuracy: 0.5401 - val_loss: 1.1870 - val_accuracy: 0.5540 - lr: 1.0000e-04\n",
      "Epoch 47/48\n",
      "225/225 [==============================] - 47s 209ms/step - loss: 1.1966 - accuracy: 0.5425 - val_loss: 1.1748 - val_accuracy: 0.5557 - lr: 1.0000e-04\n",
      "Epoch 48/48\n",
      "225/225 [==============================] - 47s 208ms/step - loss: 1.1929 - accuracy: 0.5439 - val_loss: 1.1644 - val_accuracy: 0.5598 - lr: 1.0000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x27fe9404730>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 48\n",
    "model.fit_generator(generator=train_set , steps_per_epoch=train_set.n//train_set.batch_size,\n",
    "                                epochs=epochs,\n",
    "                                validation_data = test_set,\n",
    "                                validation_steps = test_set.n//test_set.batch_size,\n",
    "                                callbacks=callbacks_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41ad35dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 3s 48ms/step - loss: 1.1644 - accuracy: 0.5601\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1644164323806763, 0.5601471662521362]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_set)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
